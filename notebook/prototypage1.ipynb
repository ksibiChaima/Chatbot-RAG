{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c14d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import psycopg\n",
    "from psycopg import Cursor\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717db55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env\")  # optional, if you store DB URL in .env\n",
    "\n",
    "# PostgreSQL connection string\n",
    "DB_CONNECTION_STR = os.getenv(\"DATABASE_URL\") or \"postgresql://postgres:chaima@localhost:5432/chatbot_rag\"\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\chaym\\Desktop\\projet_Ai\\Chatbot-RAG\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"TRANS_TXT\"\n",
    "conversation_file_path = DATA_DIR / \"017_00000012.txt\"\n",
    "\n",
    "if not DATA_DIR.is_dir():\n",
    "    raise FileNotFoundError(f\"DATA_DIR '{DATA_DIR}' not found.\")\n",
    "\n",
    "# Ollama configuration\n",
    "OLLAMA_URL = \"http://localhost:11434\"\n",
    "OLLAMA_EMBED_MODEL = \"nomic-embed-text\" # Embedding model\n",
    "OLLAMA_GEN_MODEL = \"gemma3:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into lines (sentences) =>Each line becomes one embedding vector.\n",
    "def create_conversation_list(file_path: str) -> list[str]:\n",
    "    \"\"\"Read text file and filter out line prefixes and empty lines.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"latin-1\") as file:\n",
    "        text = file.read()\n",
    "        text_list = text.split(\"\\n\")\n",
    "        filtered_list = [\n",
    "            line.removeprefix(\"     \")\n",
    "            for line in text_list\n",
    "            if not line.startswith(\"<\") and line.strip() != \"\"\n",
    "        ]\n",
    "    return filtered_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#def calculate_embeddings(corpus:str,client: OpenAI)->list[float]:\n",
    " #  embeddings=client.embeddings.create(input=corpus,model=model,encoding_format=\"float\").data\n",
    "  #  return embeddings[0].embedding  \n",
    "\n",
    "def calculate_embeddings(text: str) -> list[float]:\n",
    "    \"\"\"Generate embeddings using Ollama local API.\"\"\"\n",
    "    payload = {\"model\": OLLAMA_EMBED_MODEL, \"prompt\": text}\n",
    "    resp = requests.post(f\"{OLLAMA_URL}/api/embeddings\", json=payload)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()[\"embedding\"]\n",
    "    else:\n",
    "        raise Exception(f\"Ollama embedding error: {resp.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1c678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_embedding(corpus: str, embedding: list[float], cursor):\n",
    "    cursor.execute(\n",
    "        \"\"\"INSERT INTO embeddings (corpus, embedding) VALUES (%s, %s)\"\"\",\n",
    "        (corpus, embedding)\n",
    "    )\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed9535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##définir une fonnction similar_corpus qui prend en entrée un texte et renvoie les textes similaires dans la base de données\n",
    "#..à compléter\n",
    "#def similar_corpus(input_corpus:str, client:OpenAI, db_connection_str:str)->tuple[int, str,list[float]]:     \n",
    "# -------------------------\n",
    "# introduire une requête pour interroger\n",
    "# -------------------------\n",
    "def similar_corpus(input_text: str, db_connection_str: str, top_k: int = 5):\n",
    "    \"\"\"Return top_k similar documents to input_text.\"\"\"\n",
    "    query_embedding = calculate_embeddings(input_text)\n",
    "    with psycopg.connect(db_connection_str) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT \n",
    "                    id,\n",
    "                    corpus,\n",
    "                    1 - (embedding <=> %s::vector) AS similarity\n",
    "                FROM embeddings\n",
    "                ORDER BY similarity DESC\n",
    "                LIMIT %s;\n",
    "            \"\"\", (query_embedding, top_k))\n",
    "            results = cur.fetchall()\n",
    "    return results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374c19c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 lines to embed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting embeddings: 100%|██████████| 43/43 [01:37<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All embeddings inserted successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with psycopg.connect(DB_CONNECTION_STR) as conn:\n",
    "    conn.autocommit = True\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        # Drop old table if exists\n",
    "        cur.execute(\"DROP TABLE IF EXISTS embeddings;\")\n",
    "\n",
    "        # Enable pgvector extension\n",
    "        cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "\n",
    "        # Create table\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS embeddings (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                corpus TEXT,\n",
    "                embedding VECTOR(768)\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "        # Load conversation and compute embeddings\n",
    "        corpus_list = create_conversation_list(conversation_file_path)\n",
    "        print(f\"Found {len(corpus_list)} lines to embed.\")\n",
    "\n",
    "        for idx, corpus in enumerate(tqdm(corpus_list, desc=\"Inserting embeddings\")):\n",
    "            embedding = calculate_embeddings(corpus)\n",
    "            save_embedding(corpus, embedding, cur)\n",
    "\n",
    "        conn.commit()\n",
    "        print(\"All embeddings inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5971531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Résultats similaires ---\n",
      "ID: 5\n",
      "Texte: c: e c'est pour savoir si la fac pendant l'été e a des professeurs ou des des gens qui font des stages de de perfectionnement en anglais et en espagnol\n",
      "Similarité: 0.8272\n",
      "\n",
      "ID: 15\n",
      "Texte: h: en anglais ou en espagnol pendant l'été\n",
      "Similarité: 0.7816\n",
      "\n",
      "ID: 13\n",
      "Texte: h: et elle souhaiterais se perfectionner\n",
      "Similarité: 0.7323\n",
      "\n",
      "ID: 25\n",
      "Texte: c: son espagnol\n",
      "Similarité: 0.7060\n",
      "\n",
      "ID: 17\n",
      "Texte: h: oui alors e la fac de e de lettre et de langues se trouve à Lorient donc il faudrait plutôt  voir avec Lorient pour e savoir si ils organisent des stages mais en tout cas fac est fermée du 23 juillet au 23 août\n",
      "Similarité: 0.7042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The user question is ALSO converted into a vector.\n",
    "request=\"Existe-t-il des stages de perfectionnement en anglais et en espagnol ?\"\n",
    "results = similar_corpus(request, DB_CONNECTION_STR)\n",
    "\n",
    "print(\"\\n--- Résultats similaires ---\")\n",
    "for r in results:\n",
    "    print(f\"ID: {r[0]}\\nTexte: {r[1]}\\nSimilarité: {r[2]:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3863413",
   "metadata": {},
   "source": [
    "Generates a response using Ollama LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "451c9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Generate RAG response\n",
    "# ---------------------------\n",
    "def generate_rag_response(question: str, db_connection_str: str) -> str:\n",
    "    # 1. Retrieve similar docs\n",
    "    similar_docs = similar_corpus(question, db_connection_str, top_k=3)\n",
    "    context = \"\\n\\n---\\n\\n\".join([doc[1] for doc in similar_docs])\n",
    "\n",
    "    # 2. Build prompt\n",
    "    prompt = f\"\"\"Tu es un assistant qui répond aux questions basées UNIQUEMENT sur les documents fournis.\n",
    "\n",
    "Documents de référence:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Réponds de manière précise en te basant sur les documents. Si l'information n'y est pas, dis-le clairement.\"\"\"\n",
    "\n",
    "    # 3. Generate answer with Ollama LLM\n",
    "    payload = {\"model\": OLLAMA_GEN_MODEL, \"prompt\": prompt, \"stream\": False}\n",
    "    resp = requests.post(f\"{OLLAMA_URL}/api/generate\", json=payload)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()[\"response\"]\n",
    "    else:\n",
    "        raise Exception(f\"Ollama LLM error: {resp.text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Question ---\n",
      "Est-ce que la faculté est ouverte pendant l’été ?\n",
      "\n",
      "--- Answer ---\n",
      "Oui, la faculté est ouverte pendant l’été.\n"
     ]
    }
   ],
   "source": [
    "question = \"Est-ce que la faculté est ouverte pendant l’été ?\"\n",
    "answer = generate_rag_response(question, DB_CONNECTION_STR)\n",
    "print(\"\\n--- Question ---\")\n",
    "print(question)\n",
    "print(\"\\n--- Answer ---\")\n",
    "print(answer)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d647eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Question ---\n",
      "Où se trouve l’organisme English Connection ?\n",
      "\n",
      "--- Answer ---\n",
      "Selon le document « h : je ne sais pas oh vous allez trouver ça dans le dans l'annuaire hein », l'organisme English Connection se trouve dans l'annuaire.\n"
     ]
    }
   ],
   "source": [
    "question = \"Où se trouve l’organisme English Connection ?\"\n",
    "\n",
    "answer = generate_rag_response(question, DB_CONNECTION_STR)\n",
    "print(\"\\n--- Question ---\")\n",
    "print(question)\n",
    "print(\"\\n--- Answer ---\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
